{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b060481",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "The [Proteomics Data Mining Challenge 2020](https://proteomicsnews.blogspot.com/2020/02/proteomics-data-mining-challenge-2020.html) was a community challenge to (re)analyze public amyotrophic lateral sclerosis (ALS) proteomics to find putative biomarkers. ALS is a progressive nervous system disease that affects nerve cells in the brain and spinal cord, causing loss of muscle control, eventually leading to death.\n",
    "\n",
    "Proteomics data for 33 individuals with ALS and 30 healthy controls were analyzed by open modification searching using the ANN-SoLo spectral library search engine. Protein abundances were calculated using spectral counting.\n",
    "\n",
    "**Can we build a random forest classifier to predict ALS disease state? Can we derive relevant biomarkers from the random forest model?**\n",
    "\n",
    "Start by loading the features file and explore the protein abundance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8632cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data table:\n",
    "X = pd.read_csv(\"../data/als_features.csv\", index_col=\"filename\")\n",
    "# Read the class labels:\n",
    "y = pd.read_csv(\"../data/als_filenames.csv\", index_col=\"filename\")\n",
    "# Make sure both files are sorted in the same order:\n",
    "y = y.reindex(index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454eeee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {len(X.columns):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc99da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef9cd3",
   "metadata": {},
   "source": [
    "We have a lot more features $k$ than samples $n$. This is very common when analyzing molecular data, where thousands to tens of thousands of analytes can be measured in a single experiment.\n",
    "\n",
    "**What might happen for data with $k >> n$? Which kind of machine learning solutions do we have and what are their strengths/weaknesses?**\n",
    "\n",
    "Now we will train a random forest classifier. To evaluate the model performance we will split the data into a train, validation, and test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd689cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test set:\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X.values, y[\"label\"].map({\"A\": 0, \"H\": 1}).values, test_size=11, random_state=0,\n",
    ")\n",
    "# Further split the train set into a train and validation set:\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=11, random_state=0,\n",
    ")\n",
    "\n",
    "print(f\"Number of samples in the train set: {X_train.shape[0]}\")\n",
    "print(f\"Number of samples in the validation set: {X_val.shape[0]}\")\n",
    "print(f\"Number of samples in the test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e52f3",
   "metadata": {},
   "source": [
    "We will build a random forest model including two different types of feature selection:\n",
    "\n",
    "- No feature selection.\n",
    "- Select the $k'$ best features using a statistical test.\n",
    "- Reduce the dimensionality to $k'$ using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d8895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that combines preprocessing and an RF classifier:\n",
    "k = 20\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    VarianceThreshold(),\n",
    "    # Uncomment the following lines one by one:\n",
    "    # No feature selection: Don't uncomment anything.\n",
    "#     SelectKBest(k=k),\n",
    "#     PCA(n_components=k, random_state=0),\n",
    "    RandomForestClassifier(random_state=0),\n",
    ")\n",
    "\n",
    "# Train the model on the train set:\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate the model on the validation set:\n",
    "y_pred = model.predict_proba(X_val)\n",
    "print(f\"Validation AUC = {roc_auc_score(y_val, y_pred[:, 1]):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497bd37",
   "metadata": {},
   "source": [
    "Write down the validation AUC for each of the different models:\n",
    "\n",
    "- No feature selection: AUC = ???\n",
    "- $k$ best feature selection: AUC = ???\n",
    "- PCA: AUC = ???\n",
    "\n",
    "**Which method achieved the best performance? Why?**\n",
    "\n",
    "Bonus: Try different values for $k$ for PCA and best feature selection. Which AUC scores do you get? What does this indicate?\n",
    "\n",
    "Now that we have completed model selection, evaluate the best model on the test set. Remember, we only do this at the very end of our modeling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the final model specification here:\n",
    "model = make_pipeline(\n",
    "    # ...\n",
    "    StandardScaler(),\n",
    "    VarianceThreshold(),\n",
    ")\n",
    "\n",
    "# Retrain the final model on the train set:\n",
    "model.fit(X_train, y_train)\n",
    "# Evaluate the final model on the test set:\n",
    "y_pred = model.predict_proba(X_test)\n",
    "auc_test = roc_auc_score(y_test, y_pred[:, 1])\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred[:, 1])\n",
    "print(f\"Test AUC = {auc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2097cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the ROC curve:\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fpr, tpr, label=f\"AUC (test) = {auc_test:.3f}\", marker=\"o\")        \n",
    "ax.plot([0, 1], [0, 1], c=\"black\", ls=\"--\")\n",
    "ax.legend(loc=\"lower right\", frameon=False)\n",
    "\n",
    "ax.set_xlim(0, 1.05)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "\n",
    "sns.despine(ax=ax)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc474c7c",
   "metadata": {},
   "source": [
    "What is the model performance on the test set compared to model performance on the validation set? Can you explain this?\n",
    "\n",
    "**Were we able to successfully train a classifier to predict ALS status?**\n",
    "\n",
    "**What are strategies to further improve model performance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a4de5",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "\n",
    "Information on the most important features used in the random forest can provide insights into relevant biomarkers. Random forest feature importances are computed as the mean and standard deviation of accumulation of the impurity decrease within each tree. This tells us roughly how valuable splitting on that feature was in making the final prediction. \n",
    "\n",
    "**Let's look at the most important features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the retained features after feature selection:\n",
    "selected_features = X.columns[model[\"variancethreshold\"].get_support()]\n",
    "selected_features = selected_features[model[\"selectkbest\"].get_support()]\n",
    "# Match features to feature importances:\n",
    "feature_importances = pd.Series(\n",
    "    model[\"randomforestclassifier\"].feature_importances_,\n",
    "    index=selected_features\n",
    ")\n",
    "# Sort by descending feature importance:\n",
    "feature_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "feature_importances.plot.bar(legend=False, ax=ax)\n",
    "\n",
    "ax.set_ylim(0, ax.get_ylim()[1])\n",
    "\n",
    "ax.set_xlabel('Protein')\n",
    "ax.set_ylabel('Feature importance')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
