{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2749ff-6808-4be6-a75b-09e61df3a24a",
   "metadata": {},
   "source": [
    "# Lab 1: Getting Started with Machine Learning\n",
    "\n",
    "## Labs for this short course\n",
    "Each session will be split between lectures and a hands-on lab session like this one. We aim for these lab sessions serve multiple purposes:\n",
    "- Provide a space to explore the\n",
    "- concepts discussed in the lectures.\n",
    "- See and use tools that rely on the machine learning methods we discuss.\n",
    "- Give a friendly first glimpse into the programming needed to develop machine learning models.\n",
    "\n",
    "Some of our lab sessions (like this one) will use an environment called a [Jupyter notebook](https://jupyter.org/). Other sessions will be a guided walk-through the operation of specific mass spectrometry tools that use specific machine learning methods under the hood. Jupyter notebooks provide a way to marry text and code—a concept call *literate programming*—providing a rich interactive document for us to explore with. While you could install Jupyter on your computer, we are using a service called [Binder](https://mybinder.org/) to run these Jupyter notebooks on a borrowed computer in the cloud; thus, there are no installation requirements for the labs aside from a web browser.\n",
    "\n",
    "This lab will focus on familiarizing us with the Jupyter notebook interface, a short introduction to programming in Python, and exploring the \"bias-variance\" tradeoff.\n",
    "\n",
    "## Exercise 1: Meet your group!\n",
    "Everyone should have been assigned a random group for our lab sessions. Find the other 3–4 folks in your group and introduce yourself! This is an excellent time to help each other and learn together. Over the next 5 minutes, go around and introduce yourself with the following info and anything else you want to share:\n",
    "1. Your name (don't hesitate to gently correct mispronunciations!)\n",
    "2. Your preferred pronouns (he/him, she/her, them/they, ...)\n",
    "3. Where you are from, as specific as you want to be.\n",
    "4. Why are you interested in machine learning?\n",
    "\n",
    "Your group should be the first folks you look at to answer questions and discuss the excersises during the labs. However, if you do get stuck or have a remaining question, don't hesistate to ask for help! Use your post-it notes (we should have already talked about what the colors mean) to signal that your group needs help and one of the instructors will be over as soon as possible to assist.\n",
    "\n",
    "## Exercise 2: Introducing Jupyter notebooks\n",
    "We chose to use Jupyter notebook environments with Binder, because they provide a way for us to explore the machine learning method we discuss with little-to-no setup required. However, the notebook interface can be intimidating, particularly if you've never programmed before. If this describes how you're feeling, please don't worry; We've tried to design these labs to be approachable by anyone—with or without coding experience—once they understand the Jupyter notebook interface at a high-level.\n",
    "\n",
    "### The Jupyter Lab interface\n",
    "Jupyter notebooks allow us to switch between writing text (in a syntax called \"markdown\") and code using the concept of cells. The markdown cells are where we've written the prose for excersises. In fact, the text you're reading right now is contained in a markdown cell. Here are the different parts of a Jupyter notebook:\n",
    "\n",
    "![notebook](images/blank-notebook-ui.png)\n",
    "\n",
    "### Running code in Jupyter notebooks\n",
    "Code cells contain code that we can run. When we run or execute a code cell, the computer reads the code that is written in it and uses it as a set of instructions to do *something*—whatever, we've programmed it to do. Many of the exercises involve running code that we've already written and modifying it in specific ways to see what happens. Throughout the labs, you'll see two types of code: Python and shell commands (commands you would run from the command line or terminal).\n",
    "\n",
    "A code cell is indicated with a `[x]:` beside it, where `x` is blank if the code cell has never been run. After a code cell has been run `x` indicates the order in which that code cell was run, among all of the other code cells in the notebook. Some code cells will also output text or images when they are run. These outputs appear below the code cell that generated them and are updated each time the code cell is run. \n",
    "\n",
    "To run the example code cell below, click on the cell and press the \"Run\" button in the toolbar, or pressing ⌘Cmd + Enter (MacOS) or Ctrl + Enter (Windows). \n",
    "\n",
    "**Go ahead a run the cell below. What happened?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0893c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"I just ran this cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc36e355",
   "metadata": {},
   "source": [
    "Throughout these labs, we will modify parts of existing code cells to see what happens. Below is a code cell that will create a plot which we can modify. Note that parts following `#`s are comments and have no affect on the code itself. Most of our Jupyter notebooks will begin with an series of `import` statements, which allow us to load the functionality required for the session.\n",
    "\n",
    "For this session, we only need the following import.\n",
    "\n",
    "**Run the cell below with ⌘Cmd + Enter (MacOS) or Ctrl + Enter (Windows):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8c88f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ffe896",
   "metadata": {},
   "source": [
    "With the functionality for our current session loaded, **try running the code below**. If your see a message that says `NameError`, please verify that you've run the code cell above.\n",
    "\n",
    "**Try experimenting with values for the parameter**. To change the values, type any number you want in place of the `1`. You can also try non-numbers, but you'll receive an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397f710f-cbc0-42d6-a44f-96201a8b2931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the value of parameter and see what happens:\n",
    "parameter = 1\n",
    "\n",
    "# After you change the above parameter, run the code.\n",
    "# The plot generated by the function below should change!\n",
    "src.session_1.make_first_plot(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bc1998",
   "metadata": {},
   "source": [
    "Which function do you think $f(X)$ describes? *The answer is at the bottom of this notebook.*\n",
    "\n",
    "### Running command line programs in Jupyter notebooks\n",
    "Finally, we can also execute command line programs from within a Jupyter notebook code cell. In later labs we'll explore command line programs like Percolator in detail. There are multiple ways to run command line programs in a Jupyter notebook. The easiest is to prefix your code with an exclamation point `!`.\n",
    "\n",
    "**Run the following code cell to print the help for Percolator.** Please note that you don't really need to pay attention to what the help message says, just that it was printed from the Percolator command line program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!percolator --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846de02",
   "metadata": {},
   "source": [
    "## Exercise 3: A brief introduction to Python\n",
    "\n",
    "Python is a general purpose programming language that is very popular for machine learning and data science. We have no expectation that you've programmed in any language before, but as you saw in the previous exerciese, we will often be working together on small modifications to Python code in these labs. We chose this format, so that everyone would be exposed to Python code and that these labs could serve as a jumping-off point to pursue your interests after the course. However, we'll need to introduce a little bit of how Python works to maximize your experience.\n",
    "\n",
    "### Variables are assigned with the `=` symbol.\n",
    "In Python we assign *values* to *variables* as a way to make the computer remember something that we choose. In Python and many programming languages, *values* are assigned to *variables* using the `=` symbol. The values we can assign take many forms, which we call *data types*. We will mostly be working with numeric data types like `1`,`10`, `100382`, `2.35`, `3e4`.\n",
    "\n",
    "This code below assigns the value `3.14159` to the variable `pi`, then uses the `print()` function to show us the value we've assigned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbcf739",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 3.14159\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906257bb",
   "metadata": {},
   "source": [
    "There are also non-numeric data types that we'll use less frequently in these labs. One example of these strings, which are collections of characters enclosed in quotation marks (single quotes `'` or double quotes `\"` will work). \n",
    "\n",
    "For example, we can assign the string `\"awesome\"` to the variable `mass_spec`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558d14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_spec = \"awesome\"\n",
    "print(mass_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f57839",
   "metadata": {},
   "source": [
    "Additionally we can change the value of a variable after it's first assigned. In this example we assign the variable `pi` the value of `3.14159`, then we reassign the variable `pi` the value of `\"whoops\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dd8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 3.14159\n",
    "print(\"First pi was:\", pi)\n",
    "\n",
    "pi = \"whoops\"\n",
    "print(\"Now pi is:   \", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c31db",
   "metadata": {},
   "source": [
    "**Experiment with assigning your own variables in the empty code cell below.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e905202",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a05cf8",
   "metadata": {},
   "source": [
    "**Before you run the next code cell, what do you predict will happen?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40336b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = 3.14159\n",
    "cherry = pi\n",
    "cherry = cherry + 1\n",
    "print(cherry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddb668",
   "metadata": {},
   "source": [
    "### Functions use inputs to produce outputs\n",
    "\n",
    "Just like the functions we're trying to estimate using machine learning, functions in Python can take inputs and turn them into outputs. We typically call the inputs *arguments*. In some exercises you'll need to change the values of arguments to explore how a function behaves. One example of a function we've used already is `print()` which prints the values of the variables you give it.\n",
    "\n",
    "We can also define our own custom function using the `def` keyword:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  The function\n",
    "#      name        arguments\n",
    "#       |              |\n",
    "#       |       +------+--------+\n",
    "#       V       V      V        V\n",
    "def my_function(X, multiplier, power):\n",
    "    \"\"\"I am a docstring.\n",
    "\n",
    "    I contains information about the function.\n",
    "    \"\"\"\n",
    "    # We use arguments like as variables in the function.\n",
    "    Y = multiplier * X**power  # ** indicates an exponent.\n",
    "\n",
    "    # The return keyword specifies the output\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a7e64",
   "metadata": {},
   "source": [
    "Once its defined, we can then use the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = my_function(10, 2, 0.5)  # 2(10^0.5)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c44fb",
   "metadata": {},
   "source": [
    "**Write a function that calculates the mean of three numbers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b70c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83f7c5d4",
   "metadata": {},
   "source": [
    "## Exploring the bias-variance tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071717a5",
   "metadata": {},
   "source": [
    "We're now going to revisit our peptide retention time data and use it to get a better understanding of the bias-variance trade-off. The code below fits a model with one hyperparameter `k` that controls its flexibility to our peptide retention time dataset from [Zolg et al](https://doi.org/10.1002/pmic.201700263). As a group, explore what happens when you change `k` and discuss your observations. \n",
    "\n",
    "**Explore values of k between 1 and 10**\n",
    "- What changes do you see in the model fit (the line in the first two panels) when you change k?\n",
    "- What value of k would you choose for a final model based on these results?\n",
    "- Do low values of k result in high bias or high variance?\n",
    "- Do high values of k result in high bias or high variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the value of k by replace None with an between 0 and 29:\n",
    "k = 13\n",
    "\n",
    "# This function fits a model, then plots the results.\n",
    "src.session_1.fit_model_to_ret_times(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e48da-2cda-4aaf-9322-2f25b3ea311b",
   "metadata": {},
   "source": [
    "## The Prime Directive\n",
    "\n",
    "Recall Will's prime directive of ML: \n",
    "> Only evaluate your models on data that has never been used for training.\n",
    "\n",
    "Now we're going to explore why it is so important and what happens when we ignore it!\n",
    "\n",
    "First, we'll load some data that represents a biomarker panel for a disease. Each **feature** in our dataset is a measurement of one out of 100 analytes and each **example** is one patient. The **output** variable indicates whether or not each patient was diagnosed with our disease of interest by some other means. In the code cell below, we load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473b403-bc37-4ec5-8da9-041c57f5e5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_all are the features\n",
    "# y_all is the labels\n",
    "X_all, y_all = load_data()\n",
    "\n",
    "print(f\"Loaded {X_all.shape[0]} features for {X_all.shape[1]} patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6daf94-4e6e-4fda-8512-5bc291c44818",
   "metadata": {},
   "source": [
    "We now split our data into a training and a test set, before doing anything. We will use the training set for all of our model training tasks, then use our test set only for our final evaluation. \n",
    "\n",
    "To do this, we use `train_test_split` from the scikit-learn package `sklearn`. Scikit-learn is the *de facto* Python package for many machine learning algorithms and tools. \n",
    "\n",
    "The code below splits our data once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "534a3ddc-1101-49cf-bd86-bea25810de77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Split arrays or matrices into random train and test subsets.\n",
       "\n",
       "Quick utility that wraps input validation,\n",
       "``next(ShuffleSplit().split(X, y))``, and application to input data\n",
       "into a single call for splitting (and optionally subsampling) data into a\n",
       "one-liner.\n",
       "\n",
       "Read more in the :ref:`User Guide <cross_validation>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*arrays : sequence of indexables with same length / shape[0]\n",
       "    Allowed inputs are lists, numpy arrays, scipy-sparse\n",
       "    matrices or pandas dataframes.\n",
       "\n",
       "test_size : float or int, default=None\n",
       "    If float, should be between 0.0 and 1.0 and represent the proportion\n",
       "    of the dataset to include in the test split. If int, represents the\n",
       "    absolute number of test samples. If None, the value is set to the\n",
       "    complement of the train size. If ``train_size`` is also None, it will\n",
       "    be set to 0.25.\n",
       "\n",
       "train_size : float or int, default=None\n",
       "    If float, should be between 0.0 and 1.0 and represent the\n",
       "    proportion of the dataset to include in the train split. If\n",
       "    int, represents the absolute number of train samples. If None,\n",
       "    the value is automatically set to the complement of the test size.\n",
       "\n",
       "random_state : int, RandomState instance or None, default=None\n",
       "    Controls the shuffling applied to the data before applying the split.\n",
       "    Pass an int for reproducible output across multiple function calls.\n",
       "    See :term:`Glossary <random_state>`.\n",
       "\n",
       "shuffle : bool, default=True\n",
       "    Whether or not to shuffle the data before splitting. If shuffle=False\n",
       "    then stratify must be None.\n",
       "\n",
       "stratify : array-like, default=None\n",
       "    If not None, data is split in a stratified fashion, using this as\n",
       "    the class labels.\n",
       "    Read more in the :ref:`User Guide <stratification>`.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "splitting : list, length=2 * len(arrays)\n",
       "    List containing train-test split of inputs.\n",
       "\n",
       "    .. versionadded:: 0.16\n",
       "        If the input is sparse, the output will be a\n",
       "        ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
       "        input type.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> import numpy as np\n",
       ">>> from sklearn.model_selection import train_test_split\n",
       ">>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
       ">>> X\n",
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7],\n",
       "       [8, 9]])\n",
       ">>> list(y)\n",
       "[0, 1, 2, 3, 4]\n",
       "\n",
       ">>> X_train, X_test, y_train, y_test = train_test_split(\n",
       "...     X, y, test_size=0.33, random_state=42)\n",
       "...\n",
       ">>> X_train\n",
       "array([[4, 5],\n",
       "       [0, 1],\n",
       "       [6, 7]])\n",
       ">>> y_train\n",
       "[2, 0, 3]\n",
       ">>> X_test\n",
       "array([[2, 3],\n",
       "       [8, 9]])\n",
       ">>> y_test\n",
       "[1, 4]\n",
       "\n",
       ">>> train_test_split(y, shuffle=False)\n",
       "[[0, 1, 2], [3, 4]]\n",
       "\u001b[0;31mFile:\u001b[0m      ~/mambaforge/lib/python3.12/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# First load the function we need from scikit-learn:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create our train and test splits:\n",
    "# X_train and y_train are our training split\n",
    "# X_test and y_test are our test split\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(\n",
    "    X_all, y_all, test_size=50, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4159110c-af09-42c7-8c80-e292d8ee10ae",
   "metadata": {},
   "source": [
    "Here we split the training data again, so that we have a held-out validation set on which to evaluate the different **hyperparameters** we can choose for our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3160b-41e9-47eb-9c22-9dbbdfabebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our train and validation splits:\n",
    "# X_train and y_train are our training split\n",
    "# X_val and y_val are our test split\n",
    "(X_train, y_train), (X_test, y_test) = train_test_split(\n",
    "    X_all, y_all, test_size=20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19388068-cde6-48b8-98da-6cbf0c052a60",
   "metadata": {},
   "source": [
    "Finally before modeling, let's visulize our training set using principal component analysis (PCA). PCA allows us to reduce the dimensionality of our dataset from the 100 features, down to two, which we can plot and explore. It is always a good idea to perform some exploratory analysis to learn about your dataset before modeling.\n",
    "\n",
    "Again, we use scikit-learn, but this time it is to perform PCA. We also use another common Python package, matplotlib, to plot vizualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e00427-c66f-43b9-8eb9-10196d85c9bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Reduce the dimensionality of X_train:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_red \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce the dimensionality of X_train:\n",
    "X_red = PCA(n_components=2).fit_transform(X_train)\n",
    "\n",
    "# Create the plot:\n",
    "plt.figure()\n",
    "\n",
    "# Plot the positive examples:\n",
    "X_pos = X_red[y_train == 1, :]\n",
    "plt.scatter(X_pos[:, 0], X_pos[:, 1], label=\"positive\")\n",
    "\n",
    "# Plot the negative examples:\n",
    "X_neg = X_red[y_train == 0, :]\n",
    "plt.scatter(X_neg[:, 0], X_neg[:, 1], label=\"negative\")\n",
    "\n",
    "# Add the legend:\n",
    "plt.legend()\n",
    "\n",
    "# And finally, show the plot:\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af145d-6fe3-49ab-bd07-44c69c95d6aa",
   "metadata": {},
   "source": [
    "Now we're going to build our model two ways: once ignoring Will's Prime Directive, and once following it to see how they perform. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0db97d-8711-426e-b818-53a595c38cc1",
   "metadata": {},
   "source": [
    "## Ignoring the Prime Directive\n",
    "\n",
    "We're now going to fit a classifier to our full dataset, prior to splitting data for modeling. In practice, you should never do this for a supervised learning task (or one that will be come a supervised learning task on the same data). \n",
    "\n",
    "Let's begin building our model! Once again there is a single hyperparameter what we need to pick. This time it is represented by the greek letter lambda, $\\lambda$, which we write as variable `lambda_val` below. *Note that `lambda` is a reserved keyword in Python, so "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf94d5e-6ff5-4448-9e2d-19701f4a9500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d44678f",
   "metadata": {},
   "source": [
    "## Answers\n",
    "*What the function do you think $f(X)$ describes?* If we call our parameter $p$, then $f(X) = X\\sin(pX)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
